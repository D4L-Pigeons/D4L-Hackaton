{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models',\n",
       " 'main.py',\n",
       " 'utils',\n",
       " '__pycache__',\n",
       " '__init__.py',\n",
       " 'run_pcm_mnist_experiment.py']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not \"src\" in os.listdir():\n",
    "    os.chdir(\"../../src\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /home/prz/bioml/mag/D4L-Hackaton/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'src'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(current_directory).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeptuneLogger\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Conditional MNIST dataset\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_config_from_path\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpcm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmnist_cond_trans_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     ConditionalMNIST,\n\u001b[1;32m     20\u001b[0m     get_ConditionalMnistDataloader,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Typing\u001b[39;00m\n",
      "File \u001b[0;32m~/bioml/mag/D4L-Hackaton/src/utils/config.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpaths\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CONFIG_PATH\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import scienceplots\n",
    "\n",
    "# plt.style.use(\"science\")\n",
    "\n",
    "# Neptune\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "\n",
    "# Conditional MNIST dataset\n",
    "from utils.config import load_config_from_path\n",
    "from utils.data.pcm.mnist_cond_trans_dataset import (\n",
    "    ConditionalMNIST,\n",
    "    get_ConditionalMnistDataloader,\n",
    ")\n",
    "\n",
    "# Typing\n",
    "from utils.common_types import Batch\n",
    "from typing import Callable, Dict, Any, Tuple, List\n",
    "\n",
    "# Other\n",
    "import inspect\n",
    "from functools import partial\n",
    "from argparse import Namespace\n",
    "\n",
    "# Paths\n",
    "from utils.paths import CONFIG_PATH_DATA, CONFIG_PATH_MODELS\n",
    "\n",
    "# Chain model\n",
    "from models.components.chain import Chain\n",
    "\n",
    "# Neptune\n",
    "import neptune\n",
    "\n",
    "# Plotting & Callbacks\n",
    "from src.utils.evaluation.plots import (\n",
    "    plot_original_vs_reconstructed,\n",
    "    plot_images_with_conditions,\n",
    "    wrap_with_first_batch,\n",
    "    plot_latent,\n",
    "    NeptunePlotLogCallback,\n",
    "    plot_latent_with_pca_umap,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: NEPTUNE_API_TOKEN=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJmMDY1MDE0NC00Zjg3LTRiZmYtOTQwNi0xNjNlNmZjNWQ5MDkifQ==\"\n"
     ]
    }
   ],
   "source": [
    "%env NEPTUNE_API_TOKEN=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJmMDY1MDE0NC00Zjg3LTRiZmYtOTQwNi0xNjNlNmZjNWQ5MDkifQ==\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"multimodal/vaes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the NEPTUNE_API_TOKEN environment variable\n",
    "neptune_api_token = os.getenv(\"NEPTUNE_API_TOKEN\")\n",
    "\n",
    "# Check if the token is available\n",
    "if neptune_api_token is None:\n",
    "    raise ValueError(\"NEPTUNE_API_TOKEN environment variable is not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Subset\n",
    "\n",
    "train_data_cfg_file_path = CONFIG_PATH_DATA / \"pcm-mnist-02-train.yaml\"\n",
    "\n",
    "test_data_cfg_file_path = CONFIG_PATH_DATA / \"pcm-mnist-02-test.yaml\"\n",
    "\n",
    "train_data_cfg = load_config_from_path(file_path=train_data_cfg_file_path)\n",
    "cmnist_train = ConditionalMNIST(cfg=train_data_cfg)\n",
    "\n",
    "# cmnist_train = Subset(cmnist_train, list(range(1000)))\n",
    "\n",
    "cmnist_train_dataloader = get_ConditionalMnistDataloader(\n",
    "    cmnist=cmnist_train, batch_size=128, shuffle=True\n",
    ")\n",
    "\n",
    "test_data_cfg = load_config_from_path(file_path=test_data_cfg_file_path)\n",
    "cmnist_val = ConditionalMNIST(cfg=test_data_cfg)\n",
    "\n",
    "# cmnist_val = Subset(cmnist_val, list(range(1000)))\n",
    "\n",
    "cmnist_val_dataloader = get_ConditionalMnistDataloader(\n",
    "    cmnist=cmnist_val, batch_size=128, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': <Figure size 200x2000 with 10 Axes>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_images_with_conditions_wrapped_with_wrap_with_first_batch = wrap_with_first_batch(\n",
    "    plot_images_with_conditions,\n",
    "    **vars(\n",
    "        Namespace(\n",
    "            imgs_name=\"img\",\n",
    "            conditions_name=\"condition_token_ids\",\n",
    "            condition_values_name=\"condition_values\",\n",
    "            disp_batch_size=10,\n",
    "            disp_n_latent_samples=1,\n",
    "            filename_comp=\"filename\",\n",
    "            disp_img_size=2,\n",
    "            y_title_shift=0.91,\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig = plot_images_with_conditions_wrapped_with_wrap_with_first_batch(\n",
    "    dataloader=cmnist_val_dataloader, processing_function=lambda batch: batch\n",
    ")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prior_sampled_imgs_with_conditions_wrapped = wrap_with_first_batch(\n",
    "    plot_images_with_conditions,\n",
    "    **vars(\n",
    "        Namespace(\n",
    "            filename_comp=\"embeddings_plot\",\n",
    "            imgs_name=\"img\",\n",
    "            conditions_name=\"condition_token_ids\",\n",
    "            condition_values_name=\"condition_values\",\n",
    "            disp_batch_size=10,\n",
    "            disp_n_latent_samples=16,\n",
    "            disp_img_size=2,\n",
    "            y_title_shift=0.91,\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "plot_sample_prior_callback = NeptunePlotLogCallback(\n",
    "    plotting_function_taking_dataloader=plot_prior_sampled_imgs_with_conditions_wrapped,\n",
    "    command_name=\"sample-prior\",\n",
    "    neptune_plot_log_path=\"validation_plots/sample_prior\",\n",
    "    plot_file_base_name=\"sample_prior\",\n",
    "    command_dynamic_kwargs={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_original_vs_reconstructed_wrapped = wrap_with_first_batch(\n",
    "    plot_original_vs_reconstructed,\n",
    "    **vars(\n",
    "        Namespace(\n",
    "            org_imgs_name=\"img_org\",\n",
    "            reconstructed_imgs_name=\"img\",\n",
    "            num_images=10,\n",
    "            wspace=0.25,\n",
    "            hspace=0.25,\n",
    "            filename_comp=\"org_vs_reconstr\",\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "plot_reconstruction_callback = NeptunePlotLogCallback(\n",
    "    plotting_function_taking_dataloader=plot_original_vs_reconstructed_wrapped,\n",
    "    command_name=\"encode-decode\",\n",
    "    neptune_plot_log_path=\"validation_plots/reconstructed\",\n",
    "    plot_file_base_name=\"embedding\",\n",
    "    command_dynamic_kwargs={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings_callback = NeptunePlotLogCallback(\n",
    "    plotting_function_taking_dataloader=partial(\n",
    "        plot_latent,\n",
    "        **vars(\n",
    "            Namespace(\n",
    "                data_name=\"img\",\n",
    "                condition_value_name=\"condition_values\",\n",
    "                filename_comp=\"latent\",\n",
    "                condition_value_idxs=[0, 1, 2, 3, 4],\n",
    "                are_conditions_categorical=[True, True, True, True, True],\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    command_dynamic_kwargs={},\n",
    "    command_name=\"encode\",\n",
    "    neptune_plot_log_path=\"validation_plots/embeddings\",\n",
    "    plot_file_base_name=\"embedding\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_latent_with_pca_umap(\n",
    "#     processing_function: Callable,\n",
    "#     dataloader: torch.utils.data.DataLoader,\n",
    "#     data_name: str,\n",
    "#     condition_value_name: str,\n",
    "#     filename_comp: str,\n",
    "#     num_batches: None | int = None,\n",
    "#     plot_dims: Tuple[int] = (0, 1),\n",
    "#     figsize: Tuple[float, float] = (6, 6),\n",
    "#     n_components: int = 2,\n",
    "#     umap_n_neighbors: int = 15,\n",
    "#     umap_min_dist: float = 0.1,\n",
    "# ) -> List[matplotlib.figure.Figure]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  (_chain): ModuleDict(\n",
       "    (encoder): BlockStack(\n",
       "      (blocks): Sequential(\n",
       "        (0): Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=100, bias=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (posterior): GaussianPosterior()\n",
       "    (condition_embedding): ConditionEmbeddingTransformer(\n",
       "      (_condition_embedding_module): DiscreteValuedConditionEmbedding(\n",
       "        (_condition_embeddings): Embedding(6, 128, padding_idx=0)\n",
       "        (_category_embeddings): Embedding(27, 128, padding_idx=0)\n",
       "      )\n",
       "      (_transformer_encoder): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (condition_embeddings_to_logits): BlockStack(\n",
       "      (blocks): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=100, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (conditioned_prior): VectorConditionedLogitsGMPriorNLL()\n",
       "    (decoder): BlockStack(\n",
       "      (blocks): Sequential(\n",
       "        (0): Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): Linear(in_features=16, out_features=100, bias=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): Linear(in_features=100, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (2): Linear(in_features=512, out_features=784, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (reconstr_loss): ReconstructionLoss(\n",
       "      (_loss_fn): MSELoss()\n",
       "    )\n",
       "    (output-activation): StandaloneTinyModule(\n",
       "      (_tiny_module): Sigmoid()\n",
       "    )\n",
       "    (clone-input): TensorCloner()\n",
       "    (rearrange): BatchRearranger()\n",
       "    (repeat): BatchRepeater()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cfg_file_path = CONFIG_PATH_MODELS / \"pcm-04.yaml\"\n",
    "\n",
    "chain_cfg = load_config_from_path(file_path=model_cfg_file_path)\n",
    "chainae = Chain(cfg=chain_cfg)\n",
    "chainae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"keys = dict_keys(['g'])\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"g\": 5}\n",
    "f\"keys = {d.keys()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Create a Neptune logger\n",
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=neptune_api_token,\n",
    "    project=project_name,\n",
    "    name=\"cpiwae-3-09-24\",\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=500,\n",
    "    logger=neptune_logger,\n",
    "    check_val_every_n_epoch=10,\n",
    "    callbacks=[\n",
    "        plot_sample_prior_callback,\n",
    "        # plot_embeddings_callback,\n",
    "        plot_reconstruction_callback,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/multimodal/vaes/e/VAES-66\n"
     ]
    }
   ],
   "source": [
    "if trainer.logger is not None and hasattr(trainer.logger, \"experiment\"):\n",
    "    trainer.logger.experiment[f\"config/model_config.yaml\"].upload(\n",
    "        neptune.types.File(str(model_cfg_file_path))\n",
    "    )\n",
    "    trainer.logger.experiment[f\"config/train_data_config.yaml\"].upload(\n",
    "        neptune.types.File(str(train_data_cfg_file_path))\n",
    "    )\n",
    "    trainer.logger.experiment[f\"config/test_data_config.yaml\"].upload(\n",
    "        neptune.types.File(str(test_data_cfg_file_path))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prz/bioml/.venv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:316: The lr scheduler dict contains the key(s) ['monitor', 'strict'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | _chain | ModuleDict | 1.5 M  | train\n",
      "----------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "5.843     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac55316d5a8451ba687d9624095a1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prz/bioml/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/home/prz/bioml/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6909436e77744e3f901cd2331e80b433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prz/bioml/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=chainae,\n",
    "    train_dataloaders=cmnist_train_dataloader,\n",
    "    val_dataloaders=cmnist_val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/multimodal/vaes/e/VAES-66/metadata\n"
     ]
    }
   ],
   "source": [
    "# Stop the Neptune experiment after training ends\n",
    "neptune_logger.experiment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_id = \"VAES-40\"  # Replace with your run ID\n",
    "# run = neptune.init_run(\n",
    "#     project=project_name, api_token=neptune_api_token, with_id=run_id, mode=\"read-only\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.get_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run[\"training/model/checkpoints/epoch=9-step=240\"].download()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
